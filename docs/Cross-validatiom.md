Источник: https://www.helenkapatsa.ru/kross-validatsiia/

Кросс-валидация (перекрестная проверка) - это метод оценки моделей Машинного обучения путем обучения нескольких из них на подмножествах досутпных входных данных и их оценки на другом дополнительном множестве. Такая проверка используется для обнаружения Переобучения (Overfitting), т.е. неспособности распознать паттерн.

Всегда необходимо проверять стабильность предсказывающего алгоритма: нам нужна уверенность в том, что модель имеет представление о большинстве шаблонов в данных, что ее эффективность не падает от шумных данных, или другими словами, у нее низккий уровень смещения (Bias) и Дисперсии (Variance).

## Проверка
Валидация - это процесс принятия решения о том, приемлемы ли числовые результаты, определяющие предполагаемые взаимосвязи между перменными в качестве характеристик данных. Как правило, оценка Ошибки (Error) для модели выполняется после обучнения, более известного как оценка Остатков (Residuals). Мы выполняем численную оценку ошибки обучения - разницу в предсказанных и истинных ответах. Однако это только дает нам представление о том, насколько хорошо модель работает с тренировачными данными. Однако вероятно, что модель склонна к переобучению или недообучению (Underfitting). Проблема этого метода оценки заключается в том, что он не гарантирует приемлемый уровень обобщения новых неизвестных данных.

## Holdout Method
Простое решение вышеописанной проблемы заключается в удержании части обучающих данных и использование ее для оценки предсказательной способности. Ошибка сообщает затем, как наша модель работает с новыми данными или валидационным набором. Хотя этот метод не требует дополнительных вычислительных затрат и лучше, чем традиционная проверка, он все же подвержен высокой дисперсии. Неизвестно, какие точки данных попадут в набор для проверки, и результат может быть совершенно разным для каждой случайной выборки.

## K-Fold Cross Validation
Поскольку все возможные варианты загрузить в модель непросто, удержание части датасета для проверки создает проблему недообучения. Уменьшая объем обучающих данных, мы рискуем потерять важные закономерности и тенденции в наборе, что, в свою очередь, увеличивает ошибку, вызванную вмещением. Итак, нам нужен метод, который предоставляет достаточно данных для обучения модели, а также оставляет лостаточно данных для проверки. Кросс-валидация ко К блокам делает именно это.

При K-Fold проверке данные делятся на *к* подмножеств. Теперь удержание повторяется *к* раз, так что каждый из *к* подмножеств используется в качестве проверочного набора, а другие подмножества *к-1* объединяются, чтобы сформировать обучающий набор. Ошибка усредняется по всем *к* испытаниям, чтобы получить обобщенную эффективность нашей модели. Каждая точка данных попадает в набор для проверки для проверки ровно один раз и попадает в обучающий набор *к-1* раз. Это значительно снижает смещение, поскольку мы используем большую часть данных для подгонки, а также значительно сокращаем дисперсию, поскольку большая часть данных также используется в наборе для проверки. Перестановка тренировочного и тестового наборов также повышает эффективность этого метода. По умолчанию *к* равен 5 или 10, но может принимать любое другое значение.

## Стратифицировання кросс-валидация по К блокам
В некоторых случаях может быть большой естественный дисбаланс. Например, в датасете о ценах на недвижимость может быть большое количество домов с высокой ценой. Или в случае Классификации, представителей одного класса может быть в несколько раз больше, чем другого. Для таких ситуаций и делается небольшое изменение в методике перекрестной проверки, так что каждый блок содержит примерно такую же пропорцию классов. Этот вариант проверки также известен как стратифицированная крсс-валидация по К блокам.

Вышеупомянутые методы называют неисчерпывающими методами перекрестной проверки. Они не вычисляют все способы разделения исходной выборки, т.е. вам просто нужно решить, сколько подмножеств необходимо сделать. Кроме того, это приближения метода, описанного ниже, также называемого исчерпывающим методом, который вычисляет все возможные способы разделения данных на обучающие и тестовые наборы.

## Перкрестная проверка без исключения
**Leave-P-Out Cross Validation (*LPO*)** оставляет P точек данных за пределами обучающего набора, т.е. если в исходной выборке имеется N точек данных, тогда N-P выборок используются в качестве набора для проверки. Это повторяется для всех комбинаций, в которых исходный образец может быть отделен таким образом, а затем ошибка усредняется для всех испытаний, чтобы оценить общую эффективность.

Этот метод является исчерпывающим в том смысле, что он должен обучать и проверять модель для всех возможных комбинаций, а для умеренно больших Р он может стать вычислительно невыполнимым.

Частным случаем этого метода является Р = 1. Он известен как Поэлементная кросс-валидация (LOO). Этот метод предпочтительнее предыдущего, поэтому что не страдает от массивных вычислений, и количество возможных комбинаций равно количеству точек данных в исходной выборке (N).

Перекрестная проверка - очень полезный метод оценки эффективной вашей модели, особенно в тех случаях, когда вам нужно уменьшить переобучение. Это также полезно при определении Гиперпараметров при поиске наименьшей ошибки.